{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Objectives\n",
    "\n",
    "This lab will cover the following topics:\n",
    "\n",
    "- How to detect spam with Perceptrons\n",
    "- Spam detection with linear support vector machines (SVMs)\n",
    "\n",
    "Make sure this notebook and two dataset files 'sms_spam_perceptron.csv', 'sms_spam_svm.csv' are located in the same folder.\n",
    "\n",
    "Please try out the following cells and run the python code in your notebook. \n",
    "\n",
    "***\n",
    "***This is not an assignment and you do not need to submit it***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple Perceptron-based spam filter\n",
    "We will use the scikit-learn library to create a simple spam filter based on the Perceptron. The dataset we will use to test our spam filter is based on an sms spam messages collection, available at https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n",
    "\n",
    "The original dataset can be downloaded in CSV format; we proceeded to process the data contained in the CSV file, transforming it into numerical values to make it manageable by the Perceptron. Moreover, we have selected only the messages containing the 'buy' and 'sex' keywords , counting for each message (be it spam or ham) the number of occurrences of the keywords present in the text of the message. The result of our preprocessing is available in the sms_spam_perceptron.csv file.\n",
    "\n",
    "Then proceed with the loading of data from the sms_spam_perceptron.csv file, through the pandas library, extracting from the DataFrame of pandas the respective values, referenced through the iloc() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('sms_spam_perceptron.csv')\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "y = np.where(y == 'spam', -1, 1)\n",
    "\n",
    "X = df.iloc[:, [1, 2]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have assigned the class labels ham and spam (present in the .csv file in the first column of the DataFrame) to the y variable (which represents the vector of the expected values) using the iloc() method. Moreover, we have converted the previously mentioned class labels into the numerical values of -1 (in the case of spam) and +1 (in the case of ham) using the where() method of NumPy, to allow us to manage the class labels with the Perceptron.\n",
    "\n",
    "In the same way, we assigned to the X matrix the values corresponding to the sex and buy columns of the DataFrame, containing the number of occurrences corresponding to the two keywords within the message text. These values are also in numerical format, so it is possible to feed them to our Perceptron.\n",
    "\n",
    "Before proceeding with the creation of the Perceptron, we divide the input data between training data and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the train_test_split() method applied to the X and y variables, we split the dataset into two subsets, assigning a percentage of 30% of the original dataset (using the parameter test_size = 0.3) to the test values, and the remaining 70% to the training values.\n",
    "\n",
    "we can define our Perceptron by instantiating the Perceptron class of the sklearn.linear_model package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "p = Perceptron(max_iter=50, eta0=0.1, random_state=2)\n",
    "p.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the initialization phase of the Perceptron, we assigned a maximum number of iterations equal to 40 (with the max_iter = 40 parameter initialization) and a learning rate equal to 0.1 (eta0 = 0.1). Finally, we invoked the fit() method of the Perceptron, training the p object with the training data.\n",
    "\n",
    "We can now proceed to estimate the values on the test data, invoking the predict() method of the Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = p.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a consequence of the training phase on the sample data (which accounts for 70% of the original dataset), the Perceptron should now be able to correctly estimate the expected values of the test data subset (equal to the remaining 30% of the original dataset).\n",
    "\n",
    "We can verify the accuracy of the estimated values returned by the Perceptron using the sklearn.metrics package of scikit-learn as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the test data (y_test) with the predicted values (y_pred), and summing up the overall number of mismatches, we are now able to evaluate the accuracy of the predictions provided by the Perceptron.\n",
    "In our example, the percentage of accuracy is quite good (90%), since the total number of cases of incorrect classifications amounts to only three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam detection with SVMs\n",
    "\n",
    "To recap, SVMs are an example of supervised algorithms (as well as the Perceptron), whose task is to identify the hyperplane that best separates classes of data that can be represented in a multidimensional space. It is possible, however, to identify different hyperplanes that correctly separate the data from each other; in this case, the choice falls on the hyperplane that optimizes the prefixed margin, that is, the distance between the hyperplane and the data.\n",
    "\n",
    "The SVM can be considered as an extension of the Perceptron, however. While in the case of the Perceptron, our goal was to minimize classification errors, in the case of SVM, our goal instead is to maximize the margin, that is, the distance between the hyperplane and the training data closest to the hyperplane (the nearest training data is thus known as a support vector).\n",
    "\n",
    "Let's go back to our sample spam filter, and replace the Perceptron with a linear SVM. However, this time our dataset (stored in the sms_spam_svm.csv file) is not strictly linearly separable. \n",
    "\n",
    "In the same way as in the case of the Perceptron, we will proceed to load the data with pandas, associating the class labels with the corresponding -1 values (in the case of spam) and 1 (in the case of ham):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sms_spam_svm.csv')\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "y = np.where(y == 'spam', -1, 1)\n",
    "\n",
    "X = df.iloc[:, [1, 2]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been loaded, we proceed to split the original dataset into 30% test data and 70% training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can thus proceed to instantiate our SVM, importing the SVC class (which stands for support vector classifier) from the sklearn.svm package, choosing the linear classifier (kernel = 'linear'), then proceeding to the model training by invoking the fit() method, and finally estimating the test data by invoking the predict() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the accuracy of the predictions returned by the SVM algorithm, making use of the sklearn.metrics package as we did with the Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even in the presence of non-linearly separable data, we see how well the SVM algorithm behaves, since the level of accuracy of the predictions accounts to 84%, with the number of incorrect classifications accounting to only 7 cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "- Hands On AI for Cybersecurity - Detecting email cybersecurity threats with AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "***end***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
